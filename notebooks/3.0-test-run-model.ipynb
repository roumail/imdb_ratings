{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Objective__: Load the model trained using the script run_pipeline.py and do quality assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TODO__: add figure and models to git, removing from gitignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from train_model import train_model, compare_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CUTOFF = 7.5\n",
    "PROJECT_BASE_DIR = \"/home/rohail/projects/imdb_ratings/\"\n",
    "model_save_dir = \"models/\"\n",
    "plot_write_dir = \"reports/figures/\"\n",
    "idx_columns = [\"imdb_title_id\", \"title\", \"original_title\"]\n",
    "target_columns = [\"avg_vote\", \"avg_vote_flag\"]\n",
    "# determined via classification threshold\n",
    "classification_threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(os.path.join(PROJECT_BASE_DIR, model_save_dir, \"df_model.csv\"))\n",
    "y_test = pd.read_csv(os.path.join(PROJECT_BASE_DIR, model_save_dir, \"y_test.csv\"))\n",
    "x_test = pd.read_csv(os.path.join(PROJECT_BASE_DIR, model_save_dir, \"x_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnostic plots for this model can be found in the following directory: \n",
      "/home/rohail/projects/imdb_ratings/reports/figures/\n",
      "The model itself is saved in the following directory: /home/rohail/projects/imdb_ratings/models/\n",
      "\n",
      "Loading model from /home/rohail/projects/imdb_ratings/models/regression_2020_03_04_13_56.joblib\n",
      "Diagnostic plots for this model can be found in the following directory: \n",
      "/home/rohail/projects/imdb_ratings/reports/figures/\n",
      "The model itself is saved in the following directory: /home/rohail/projects/imdb_ratings/models/\n",
      "\n",
      "Loading model from /home/rohail/projects/imdb_ratings/models/classification_2020_03_04_14_58.joblib\n"
     ]
    }
   ],
   "source": [
    "# regression\n",
    "parameters = {\n",
    "    \"plot_write_dir\": os.path.join(PROJECT_BASE_DIR, plot_write_dir),\n",
    "    \"model_save_dir\": os.path.join(PROJECT_BASE_DIR, model_save_dir),\n",
    "    \"model_type\": \"regression\",  # , classification\n",
    "    \"idx_columns\": idx_columns,\n",
    "    \"test_set_size\": 0.1,\n",
    "    \"training_parameters\": {\n",
    "        \"class_weight\": \"balanced\",  # vs providing sample weight to fit --> does it make a difference?\n",
    "        \"n_jobs\": -1,\n",
    "        \"max_iter\" : 10000,\n",
    "        \"scoring\": \"balanced_accuracy\",\n",
    "    },\n",
    "}\n",
    "\n",
    "reg_model, df_reg_coefs, _, _ = train_model(\n",
    "    df_model,\n",
    "    parameters=parameters,\n",
    "    load_from_disk=\"regression_2020_03_04_13_56.joblib\"\n",
    ")\n",
    "\n",
    "# classification\n",
    "parameters.update({\"model_type\": \"classification\"})\n",
    "clf_model, df_clf_coefs, _, _ = train_model(\n",
    "    df_model,\n",
    "    parameters=parameters,\n",
    "    load_from_disk=\"classification_2020_03_04_14_58.joblib\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on test data\n",
      "       reg_rating_prediction  clf_prob_prediction\n",
      "count            6651.000000          6651.000000\n",
      "mean                7.317829             0.541427\n",
      "std                 3.213174             0.308058\n",
      "min                 1.286682             0.066496\n",
      "25%                 5.755538             0.226881\n",
      "50%                 6.915588             0.550601\n",
      "75%                 8.014299             0.853454\n",
      "max                65.003010             1.000000\n",
      "Regression and classification predictions the same? False\n",
      "Balanced accuracy for regression:  0.6700273187586469\n",
      "Balanced accuracy for classification:  0.6280635284037839\n",
      "Making predictions on sample data from train data\n",
      "       reg_rating_prediction  clf_prob_prediction\n",
      "count              32.000000            32.000000\n",
      "mean               22.449798             0.892645\n",
      "std                14.794780             0.218369\n",
      "min                 5.461126             0.230528\n",
      "25%                 9.657111             0.911928\n",
      "50%                19.085453             0.975793\n",
      "75%                29.684344             0.997517\n",
      "max                62.269180             1.000000\n",
      "Regression and classification predictions the same? False\n",
      "Balanced accuracy for regression:  0.5676328502415459\n",
      "Balanced accuracy for classification:  0.5120772946859903\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"target_columns\": target_columns,\n",
    "    \"classification_threshold\":classification_threshold, # determined from looking at diagnostic plot....\n",
    "    \"regression_threshold\": TARGET_CUTOFF,\n",
    "    \"idx_columns\": idx_columns,\n",
    "}\n",
    "\n",
    "train_movies_sample = {\n",
    "    \"The Dark Knight\",\n",
    "    \"Anchorman: The Legend of Ron Burgundy\",\n",
    "    \"The Big Lebowski\",\n",
    "    \"Batman v Superman: Dawn of Justice\",\n",
    "    \"Black Panther\",\n",
    "    \"Kabhi Khushi Kabhie Gham...\",\n",
    "    \"3 Idiots\",\n",
    "    \"The Intouchables\",\n",
    "    \"Amélie\",\n",
    "    \"The Matrix\",\n",
    "    \"The Matrix Reloaded\",\n",
    "    \"V for Vendetta\",\n",
    "    \"Kill Bill: Vol. 1\",\n",
    "    \"La vita è bella\",\n",
    "    \"Die Hard\",\n",
    "    \"Requiem for a Dream\",\n",
    "    \"Terminator 3: Rise of the Machines\",\n",
    "    \"The Terminator\",\n",
    "    \"Terminator 2: Judgment Day\",\n",
    "    \"Titanic\",\n",
    "    \"The Departed\",\n",
    "    \"Groundhog Day\",\n",
    "    \"Love in Kilnerry\",\n",
    "    \"Jinnah\",\n",
    "    \"Jawani Phir Nahi Ani\",\n",
    "    \"Bol\",\n",
    "    \"Das letzte Mahl\",\n",
    "    \"The Lives of Others\",\n",
    "    \"Das Experiment\",\n",
    "}\n",
    "\n",
    "# predict on unseen examples depending on model type...\n",
    "df_predict_test, df_predict_train  = compare_methods(\n",
    "    df_model, reg_model, clf_model, x_test, y_test, train_movies_sample, parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Regression seems to perform better in general but this might need further assessment - We can best make this assessment by continuing to add more features. I kept the number of features low to have a reasonable model training time. The current classification model, with it's optimizations takes about ~ 45 minutes to fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Going forward, I'd try two things: fit a more complicated regression model since currently I'm only fitting a simple OLS model. I could also attempt a more complex model same for classification but I think the best way forward would be to focus on engineering more features and see how performance improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg_coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      312.0\n",
       "1      132.0\n",
       "2       45.0\n",
       "3       11.0\n",
       "4       34.0\n",
       "5       20.0\n",
       "6       19.0\n",
       "7       50.0\n",
       "8       63.0\n",
       "9      148.0\n",
       "10      52.0\n",
       "11     299.0\n",
       "12     102.0\n",
       "13     146.0\n",
       "14     263.0\n",
       "15     227.0\n",
       "16     101.0\n",
       "17     171.0\n",
       "18     115.0\n",
       "19     296.0\n",
       "20      31.0\n",
       "21     125.0\n",
       "22       8.0\n",
       "23      86.0\n",
       "24     104.0\n",
       "25     216.0\n",
       "26      62.0\n",
       "27     143.0\n",
       "28     194.0\n",
       "29      61.0\n",
       "       ...  \n",
       "282     18.0\n",
       "283    144.0\n",
       "284    193.0\n",
       "285    170.0\n",
       "286    106.0\n",
       "287    231.0\n",
       "288     94.0\n",
       "289    195.0\n",
       "290    253.0\n",
       "291      4.0\n",
       "292     78.0\n",
       "293     60.0\n",
       "294    145.0\n",
       "295    276.0\n",
       "296    259.0\n",
       "297     82.0\n",
       "298     89.0\n",
       "299    112.0\n",
       "300    176.0\n",
       "301    197.0\n",
       "302    211.0\n",
       "303     84.0\n",
       "304      1.0\n",
       "305    131.0\n",
       "306     25.0\n",
       "307    250.0\n",
       "308     27.0\n",
       "309    189.0\n",
       "310    214.0\n",
       "311    122.0\n",
       "Name: coefficients, Length: 312, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(df_reg_coefs.coefficients).rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intercept</td>\n",
       "      <td>7.199475</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>primary_country_Nepal</td>\n",
       "      <td>2.429067</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>primary_country_Liechtenstein</td>\n",
       "      <td>-2.234611</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>primary_language_Quechua</td>\n",
       "      <td>2.213293</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>primary_country_Uganda</td>\n",
       "      <td>2.026378</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>primary_language_Assamese</td>\n",
       "      <td>2.019303</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>primary_language_Aymara</td>\n",
       "      <td>1.981734</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>primary_language_Marathi</td>\n",
       "      <td>1.897182</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>primary_language_Kashmiri</td>\n",
       "      <td>1.875165</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>primary_language_Russian Sign Language</td>\n",
       "      <td>1.842207</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      index  coefficients  importance\n",
       "0                                 intercept      7.199475         1.0\n",
       "95                    primary_country_Nepal      2.429067         2.0\n",
       "81            primary_country_Liechtenstein     -2.234611         3.0\n",
       "257                primary_language_Quechua      2.213293         4.0\n",
       "146                  primary_country_Uganda      2.026378         5.0\n",
       "165               primary_language_Assamese      2.019303         6.0\n",
       "166                 primary_language_Aymara      1.981734         7.0\n",
       "239                primary_language_Marathi      1.897182         8.0\n",
       "218               primary_language_Kashmiri      1.875165         9.0\n",
       "263  primary_language_Russian Sign Language      1.842207        10.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_coefs.loc[:, \"importance\"] = np.abs(df_reg_coefs.coefficients).rank(ascending = False)\n",
    "df_reg_coefs.sort_values(\"importance\", ascending = True).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-imdb] *",
   "language": "python",
   "name": "conda-env-.conda-imdb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
